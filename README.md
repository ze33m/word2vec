# word2vec with negative sampling
.....

## Предобработка исходного датасета
За датасет была взята [0x7o/taiga](https://huggingface.co/datasets/0x7o/taiga). Первичная предобработка реализована в [prep.py](prep.py). Все слова приведены к нижнему регистру, убрана пунктуация, цифры, лишние пробелы. После этого каждая строка была преобразована в список стеммизированных (для сжатия словаря) слов. 
![prep](src/prep.png)

## Преобразование токенов в числа
Так как в конечном итоге взаимодействовать с токенами мы будем с помощью чисел через эмбеддинги, а преобразовывание str -> int при каждом обращении к токену замедлит процесс обучения, было принято решение преобразовать все токены в int заранее. А словарь, в котором написано, какой токен какому числу соответствует, сохранен в виде json файла. Весь этот процесс описан в [convert_to_int.py](convert_to_int.py) 
![convert](src/convert_to_int.png)